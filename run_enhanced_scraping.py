#!/usr/bin/env python3
"""
Enhanced YouTube Comment Scraping Script
Run this to scrape 500+ comments per Indian EV OEM
"""

import os
import sys
import time
from datetime import datetime
from services.youtube_scraper import YouTubeCommentScraper

def main():
    print("ğŸï¸ Enhanced VibeAI YouTube Comment Scraper")
    print("=" * 60)
    print("This script will scrape 500+ comments for each Indian EV OEM:")
    print("â€¢ Ola Electric")
    print("â€¢ TVS iQube") 
    print("â€¢ Bajaj Chetak")
    print("â€¢ Ather")
    print("â€¢ Hero Vida")
    print("=" * 60)
    
    # Get user preferences
    target_comments = input("Enter target comments per OEM (default 500): ").strip()
    target_comments = int(target_comments) if target_comments.isdigit() else 500
    
    print(f"\nğŸ¯ Target: {target_comments} comments per OEM")
    print(f"ğŸ“Š Expected total: {target_comments * 5} comments")
    
    # Confirm before starting
    confirm = input("\nStart scraping? (y/n): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("Scraping cancelled.")
        return
    
    # Initialize scraper
    print("\nğŸš€ Initializing YouTube Comment Scraper...")
    scraper = YouTubeCommentScraper()
    
    # Run enhanced scraping
    start_time = time.time()
    print(f"\nâ° Starting enhanced scraping at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        all_data = scraper.run_enhanced_scraping(target_comments=target_comments)
        
        # Show results
        total_scraped = sum(len(comments) for comments in all_data.values())
        elapsed_time = time.time() - start_time
        
        print("\nğŸ‰ SCRAPING COMPLETED!")
        print("=" * 60)
        print("ğŸ“ˆ FINAL RESULTS:")
        
        for oem, comments in all_data.items():
            status = "âœ…" if len(comments) >= target_comments * 0.8 else "âš ï¸"  # 80% threshold
            print(f"{status} {oem}: {len(comments)} comments")
        
        print(f"\nğŸ“Š Total Comments Scraped: {total_scraped}")
        print(f"â±ï¸  Total Time: {elapsed_time/60:.1f} minutes")
        print(f"ğŸ’¾ Data saved to timestamped JSON files")
        
        # Performance metrics
        avg_per_oem = total_scraped / len(all_data)
        success_rate = (sum(1 for comments in all_data.values() if len(comments) >= target_comments * 0.8) / len(all_data)) * 100
        
        print(f"\nğŸ“‹ PERFORMANCE METRICS:")
        print(f"â€¢ Average per OEM: {avg_per_oem:.1f} comments")
        print(f"â€¢ Success Rate: {success_rate:.1f}% (80%+ of target)")
        print(f"â€¢ Comments per minute: {total_scraped/(elapsed_time/60):.1f}")
        
        if total_scraped >= target_comments * len(all_data) * 0.8:
            print("\nğŸ† SUCCESS: Target achieved for most OEMs!")
        else:
            print("\nâš ï¸  PARTIAL SUCCESS: Some OEMs may need additional scraping")
        
        print("\nğŸ’¡ TIP: Data files are saved with timestamps for easy identification")
        print("    Use these files with your Streamlit app for analysis!")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Scraping interrupted by user")
        print("Partial data may have been saved to JSON files")
    except Exception as e:
        print(f"\nâŒ Error during scraping: {e}")
        print("Check your internet connection and try again")
    
    print(f"\nğŸ Script completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
